{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09bf508",
   "metadata": {},
   "source": [
    "# **Connect Game Apriori Analysis**\n",
    "\n",
    "This script performs **Apriori Analysis** on the Connect Game dataset using Python's **`mlxtend`** library. The workflow involves preprocessing the dataset, mining frequent itemsets, and generating association rules.\n",
    "\n",
    "---\n",
    "\n",
    "## **Workflow**\n",
    "\n",
    "### **1. Dataset Preprocessing**\n",
    "- The dataset is read as a CSV file.\n",
    "- Each row represents a game state, with columns corresponding to game positions (e.g., `pos_01`, `pos_02`, ..., `pos_42`) and a `winner` column.\n",
    "- Preprocessing steps:\n",
    "  1. **Exclude the `winner` column**: This column is not used for frequent itemset mining.\n",
    "  2. **Create transactions**: Each non-null value in a row (e.g., `pos_01_X`) is treated as an item in the transaction.\n",
    "\n",
    "### **2. One-Hot Encoding**\n",
    "- The transactions are converted into a **one-hot encoded DataFrame**:\n",
    "  - Each column corresponds to an item (e.g., `pos_01_X`).\n",
    "  - Each row represents a transaction, with `True` or `False` indicating the presence or absence of an item.\n",
    "\n",
    "### **3. Frequent Itemset Mining**\n",
    "- The **Apriori algorithm** from `mlxtend` is applied to identify itemsets that occur at least a specified minimum number of times (`min_support`).\n",
    "- Example:\n",
    "  - If `min_support = 0.3`, only itemsets that appear in at least 30% of transactions are considered frequent.\n",
    "\n",
    "### **4. Association Rules Generation**\n",
    "- **Association rules** are generated from frequent itemsets using metrics like:\n",
    "  - **Support**: Proportion of transactions containing the itemset.\n",
    "  - **Confidence**: Likelihood that a consequent is present given an antecedent.\n",
    "  - **Lift**: Measure of how much the antecedent boosts the likelihood of the consequent.\n",
    "\n",
    "---\n",
    "\n",
    "## **Installation**\n",
    "\n",
    "To run the script, the following Python components need to be installed:\n",
    "\n",
    "### **Dependencies**\n",
    "1. **Python 3.6+**\n",
    "2. **Required Libraries**:\n",
    "   - `pandas`: For data handling and preprocessing.\n",
    "   - `mlxtend`: For Apriori algorithm and association rules.\n",
    "\n",
    "### **Bash Commands to Install Dependencies**\n",
    "\n",
    "#### Install `pandas`:\n",
    "```bash\n",
    "pip install pandas\n",
    "```\n",
    "\n",
    "#### Install `mlxtend`:\n",
    "```bash\n",
    "pip install mlxtend\n",
    "```\n",
    "\n",
    "#### Verify Installation:\n",
    "```bash\n",
    "pip show pandas mlxtend\n",
    "```\n",
    "\n",
    "## **Usage Instructions**\n",
    "1. Place the Connect Game dataset in the Data folder.\n",
    "\n",
    "- The dataset should be in CSV format with columns: pos_01, pos_02, ..., pos_42, winner. \n",
    "\n",
    "2.Adjust Parameters:\n",
    "\n",
    "- nrows: Limit the number of rows read from the dataset to manage memory usage.\n",
    "- min_support: Set the minimum support threshold for frequent itemsets.\n",
    "- min_confidence: Set the minimum confidence threshold for association rules.\n",
    "\n",
    "3.Run the Script:\n",
    "\n",
    "- Execute the Python script to generate frequent itemsets and association rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "616598b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "        support                                           itemsets\n",
      "0      0.876667                                       (pos_01_0.0)\n",
      "1      0.786667                                       (pos_02_0.0)\n",
      "2      0.690000                                       (pos_03_0.0)\n",
      "3      0.616667                                       (pos_04_0.0)\n",
      "4      0.770000                                       (pos_05_0.0)\n",
      "...         ...                                                ...\n",
      "33746  0.340000  (pos_02_0.0, pos_05_0.0, pos_08_0.0, pos_21_0....\n",
      "33747  0.313333  (pos_02_0.0, pos_05_0.0, pos_09_0.0, pos_21_0....\n",
      "33748  0.303333  (pos_02_0.0, pos_05_0.0, pos_20_0.0, pos_21_0....\n",
      "33749  0.316667  (pos_05_0.0, pos_08_0.0, pos_21_0.0, pos_12_0....\n",
      "33750  0.310000  (pos_05_0.0, pos_08_0.0, pos_20_0.0, pos_21_0....\n",
      "\n",
      "[33751 rows x 2 columns]\n",
      "\n",
      "Association Rules:\n",
      "                                  antecedents  \\\n",
      "0                                (pos_01_0.0)   \n",
      "1                                (pos_02_0.0)   \n",
      "2                                (pos_03_0.0)   \n",
      "3                                (pos_01_0.0)   \n",
      "4                                (pos_04_0.0)   \n",
      "...                                       ...   \n",
      "1688408  (pos_28_0.0, pos_01_0.0, pos_20_0.0)   \n",
      "1688409  (pos_28_0.0, pos_07_0.0, pos_20_0.0)   \n",
      "1688410  (pos_13_0.0, pos_28_0.0, pos_12_0.0)   \n",
      "1688411  (pos_28_0.0, pos_01_0.0, pos_12_0.0)   \n",
      "1688412              (pos_28_0.0, pos_20_0.0)   \n",
      "\n",
      "                                               consequents  \\\n",
      "0                                             (pos_02_0.0)   \n",
      "1                                             (pos_01_0.0)   \n",
      "2                                             (pos_01_0.0)   \n",
      "3                                             (pos_03_0.0)   \n",
      "4                                             (pos_01_0.0)   \n",
      "...                                                    ...   \n",
      "1688408  (pos_05_0.0, pos_08_0.0, pos_21_0.0, pos_12_0....   \n",
      "1688409  (pos_05_0.0, pos_08_0.0, pos_21_0.0, pos_12_0....   \n",
      "1688410  (pos_20_0.0, pos_05_0.0, pos_08_0.0, pos_21_0....   \n",
      "1688411  (pos_20_0.0, pos_05_0.0, pos_08_0.0, pos_21_0....   \n",
      "1688412  (pos_05_0.0, pos_08_0.0, pos_21_0.0, pos_12_0....   \n",
      "\n",
      "         antecedent support  consequent support   support  confidence  \\\n",
      "0                  0.876667            0.786667  0.720000    0.821293   \n",
      "1                  0.786667            0.876667  0.720000    0.915254   \n",
      "2                  0.690000            0.876667  0.643333    0.932367   \n",
      "3                  0.876667            0.690000  0.643333    0.733840   \n",
      "4                  0.616667            0.876667  0.580000    0.940541   \n",
      "...                     ...                 ...       ...         ...   \n",
      "1688408            0.410000            0.430000  0.310000    0.756098   \n",
      "1688409            0.433333            0.430000  0.310000    0.715385   \n",
      "1688410            0.426667            0.386667  0.310000    0.726562   \n",
      "1688411            0.436667            0.386667  0.310000    0.709924   \n",
      "1688412            0.433333            0.430000  0.310000    0.715385   \n",
      "\n",
      "             lift  representativity  leverage  conviction  zhangs_metric  \\\n",
      "0        1.044016               1.0  0.030356    1.193759       0.341842   \n",
      "1        1.044016               1.0  0.030356    1.455333       0.197627   \n",
      "2        1.063537               1.0  0.038433    1.823571       0.192713   \n",
      "3        1.063537               1.0  0.038433    1.164714       0.484386   \n",
      "4        1.072860               1.0  0.039389    2.074242       0.177161   \n",
      "...           ...               ...       ...         ...            ...   \n",
      "1688408  1.758366               1.0  0.133700    2.337000       0.731001   \n",
      "1688409  1.663685               1.0  0.123667    2.002703       0.703985   \n",
      "1688410  1.879041               1.0  0.145022    2.243048       0.815954   \n",
      "1688411  1.836009               1.0  0.141156    2.114386       0.808297   \n",
      "1688412  1.663685               1.0  0.123667    2.002703       0.703985   \n",
      "\n",
      "          jaccard  certainty  kulczynski  \n",
      "0        0.763251   0.162310    0.868274  \n",
      "1        0.763251   0.312872    0.868274  \n",
      "2        0.696751   0.451626    0.833104  \n",
      "3        0.696751   0.141420    0.833104  \n",
      "4        0.635036   0.517896    0.801069  \n",
      "...           ...        ...         ...  \n",
      "1688408  0.584906   0.572101    0.738514  \n",
      "1688409  0.560241   0.500675    0.718157  \n",
      "1688410  0.615894   0.554178    0.764143  \n",
      "1688411  0.603896   0.527049    0.755824  \n",
      "1688412  0.560241   0.500675    0.718157  \n",
      "\n",
      "[1688413 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Preprocess the Connect Game dataset\n",
    "def preprocess_connect_game(filename, nrows=300):\n",
    "    \"\"\"\n",
    "    Preprocess the Connect Game dataset into transactions.\n",
    "    Only process up to `nrows` rows.\n",
    "    \"\"\"\n",
    "    # Load the dataset with limited rows\n",
    "    data = pd.read_csv(filename, nrows=nrows)\n",
    "\n",
    "    # Drop the 'winner' column\n",
    "    if 'winner' in data.columns:\n",
    "        data = data.drop(columns=['winner'])\n",
    "\n",
    "    # Convert each row into a transaction (list of items)\n",
    "    transactions = []\n",
    "    for _, row in data.iterrows():\n",
    "        transaction = []\n",
    "        for col, value in row.items():\n",
    "            if pd.notnull(value):  # Ignore null values\n",
    "                transaction.append(f\"{col}_{value}\")\n",
    "        transactions.append(transaction)\n",
    "    \n",
    "    return transactions\n",
    "\n",
    "# Load and preprocess the dataset (only first 300 rows)\n",
    "filename = \"Data/connect-game.csv\"\n",
    "transactions = preprocess_connect_game(filename, nrows=300)\n",
    "\n",
    "# Convert transactions to one-hot encoded DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori\n",
    "min_support = 0.3  # Set minimum support threshold\n",
    "frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
    "\n",
    "# Calculate num_itemsets for older versions of association_rules\n",
    "num_itemsets = frequent_itemsets['itemsets'].apply(len).max()\n",
    "\n",
    "# Display frequent itemsets\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Generate association rules\n",
    "min_confidence = 0.7  # Set minimum confidence threshold\n",
    "rules = association_rules(frequent_itemsets, num_itemsets=num_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "# Display association rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20322671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
