{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51292de9",
   "metadata": {},
   "source": [
    "# **Pakistan Traffic Accidents Data Analysis**\n",
    "\n",
    "This script performs **Apriori Analysis** on the Pakistan Traffic Accidents dataset using Python's **`mlxtend`** library. The workflow involves preprocessing the dataset, mining frequent itemsets, and generating association rules.\n",
    "\n",
    "---\n",
    "\n",
    "## **Workflow**\n",
    "\n",
    "### **1. Dataset Preprocessing**\n",
    "- The dataset is read as a CSV file with the following structure:\n",
    "  - Columns: `Area`, `Year`, `Total number of accidents`, `Fatal Accidents`, `Non-Fatal Accidents`, `Killed`, `Injured`, `Total number of vehicles involved`.\n",
    "  - Each row represents annual accident data for a specific area.\n",
    "- **Preprocessing Steps**:\n",
    "  1. **Convert categorical data into items**: Directly add columns like `Area` and `Year` as items (e.g., `Area_Lahore`, `Year_2022`).\n",
    "  2. **Categorize numerical data**: Convert numerical columns into categorized items (e.g., `Total number of accidents` becomes `TotalAccidents_High` or `TotalAccidents_Low`).\n",
    "\n",
    "### **2. One-Hot Encoding**\n",
    "- The transactions are converted into a **one-hot encoded DataFrame**:\n",
    "  - Each column corresponds to an item (e.g., `TotalAccidents_High`).\n",
    "  - Each row represents a transaction, with `True` or `False` indicating the presence or absence of an item.\n",
    "\n",
    "### **3. Frequent Itemset Mining**\n",
    "- The **Apriori algorithm** from `mlxtend` is applied to identify itemsets that occur at least a specified minimum number of times (`min_support`).\n",
    "- **Example**:\n",
    "  - If `min_support = 0.3`, only itemsets that appear in at least 30% of transactions are considered frequent.\n",
    "\n",
    "### **4. Association Rules Generation**\n",
    "- **Association rules** are generated from frequent itemsets using metrics like:\n",
    "  - **Support**: Proportion of transactions containing the itemset.\n",
    "  - **Confidence**: Likelihood that a consequent is present given an antecedent.\n",
    "  - **Lift**: Measure of how much the antecedent boosts the likelihood of the consequent.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ada4b276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "    support                                           itemsets\n",
      "0       1.0                              (FatalAccidents_High)\n",
      "1       1.0                                     (Injured_High)\n",
      "2       1.0                                      (Killed_High)\n",
      "3       1.0                           (NonFatalAccidents_High)\n",
      "4       1.0                              (TotalAccidents_High)\n",
      "..      ...                                                ...\n",
      "58      1.0  (FatalAccidents_High, Injured_High, Killed_Hig...\n",
      "59      1.0  (FatalAccidents_High, Injured_High, NonFatalAc...\n",
      "60      1.0  (FatalAccidents_High, NonFatalAccidents_High, ...\n",
      "61      1.0  (Injured_High, NonFatalAccidents_High, Killed_...\n",
      "62      1.0  (FatalAccidents_High, VehiclesInvolved_High, N...\n",
      "\n",
      "[63 rows x 2 columns]\n",
      "\n",
      "Association Rules:\n",
      "                  antecedents  \\\n",
      "0       (FatalAccidents_High)   \n",
      "1              (Injured_High)   \n",
      "2               (Killed_High)   \n",
      "3       (FatalAccidents_High)   \n",
      "4       (FatalAccidents_High)   \n",
      "..                        ...   \n",
      "597   (VehiclesInvolved_High)   \n",
      "598  (NonFatalAccidents_High)   \n",
      "599             (Killed_High)   \n",
      "600     (TotalAccidents_High)   \n",
      "601            (Injured_High)   \n",
      "\n",
      "                                           consequents  antecedent support  \\\n",
      "0                                       (Injured_High)                 1.0   \n",
      "1                                (FatalAccidents_High)                 1.0   \n",
      "2                                (FatalAccidents_High)                 1.0   \n",
      "3                                        (Killed_High)                 1.0   \n",
      "4                             (NonFatalAccidents_High)                 1.0   \n",
      "..                                                 ...                 ...   \n",
      "597  (FatalAccidents_High, NonFatalAccidents_High, ...                 1.0   \n",
      "598  (FatalAccidents_High, VehiclesInvolved_High, K...                 1.0   \n",
      "599  (FatalAccidents_High, VehiclesInvolved_High, N...                 1.0   \n",
      "600  (FatalAccidents_High, VehiclesInvolved_High, N...                 1.0   \n",
      "601  (FatalAccidents_High, NonFatalAccidents_High, ...                 1.0   \n",
      "\n",
      "     consequent support  support  confidence  lift  representativity  \\\n",
      "0                   1.0      1.0         1.0   1.0               1.0   \n",
      "1                   1.0      1.0         1.0   1.0               1.0   \n",
      "2                   1.0      1.0         1.0   1.0               1.0   \n",
      "3                   1.0      1.0         1.0   1.0               1.0   \n",
      "4                   1.0      1.0         1.0   1.0               1.0   \n",
      "..                  ...      ...         ...   ...               ...   \n",
      "597                 1.0      1.0         1.0   1.0               1.0   \n",
      "598                 1.0      1.0         1.0   1.0               1.0   \n",
      "599                 1.0      1.0         1.0   1.0               1.0   \n",
      "600                 1.0      1.0         1.0   1.0               1.0   \n",
      "601                 1.0      1.0         1.0   1.0               1.0   \n",
      "\n",
      "     leverage  conviction  zhangs_metric  jaccard  certainty  kulczynski  \n",
      "0         0.0         inf            0.0      1.0        0.0         1.0  \n",
      "1         0.0         inf            0.0      1.0        0.0         1.0  \n",
      "2         0.0         inf            0.0      1.0        0.0         1.0  \n",
      "3         0.0         inf            0.0      1.0        0.0         1.0  \n",
      "4         0.0         inf            0.0      1.0        0.0         1.0  \n",
      "..        ...         ...            ...      ...        ...         ...  \n",
      "597       0.0         inf            0.0      1.0        0.0         1.0  \n",
      "598       0.0         inf            0.0      1.0        0.0         1.0  \n",
      "599       0.0         inf            0.0      1.0        0.0         1.0  \n",
      "600       0.0         inf            0.0      1.0        0.0         1.0  \n",
      "601       0.0         inf            0.0      1.0        0.0         1.0  \n",
      "\n",
      "[602 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Preprocess the Accident Dataset\n",
    "def preprocess_accident_data(filename, nrows=None):\n",
    "    \"\"\"\n",
    "    Preprocess the Pakistan Traffic Accident dataset into transactions.\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(filename, nrows=nrows)\n",
    "\n",
    "    # Transform each row into a transaction\n",
    "    transactions = []\n",
    "    for _, row in data.iterrows():\n",
    "        transaction = []\n",
    "\n",
    "        # Add categorical attributes\n",
    "        transaction.append(f\"Area_{row['Area']}\")\n",
    "        transaction.append(f\"Year_{row['Year']}\")\n",
    "\n",
    "        # Categorize numerical attributes\n",
    "        transaction.append(f\"TotalAccidents_{'High' if row['Total number of accidents'] > 100 else 'Low'}\")\n",
    "        transaction.append(f\"FatalAccidents_{'High' if row['Fatal Accidents'] > 10 else 'Low'}\")\n",
    "        transaction.append(f\"NonFatalAccidents_{'High' if row['Non-Fatal Accidents'] > 50 else 'Low'}\")\n",
    "        transaction.append(f\"Killed_{'High' if row['Killed'] > 5 else 'Low'}\")\n",
    "        transaction.append(f\"Injured_{'High' if row['Injured'] > 10 else 'Low'}\")\n",
    "        transaction.append(f\"VehiclesInvolved_{'High' if row['Total number of vehicles involved'] > 10 else 'Low'}\")\n",
    "\n",
    "        transactions.append(transaction)\n",
    "    \n",
    "    return transactions\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "filename = \"Data/pak-traffic-accidents-annual.csv\"\n",
    "transactions = preprocess_accident_data(filename)\n",
    "\n",
    "# Convert transactions to one-hot encoded DataFrame\n",
    "te = TransactionEncoder()\n",
    "te_array = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_array, columns=te.columns_)\n",
    "\n",
    "# Apply Apriori\n",
    "min_support = 0.80  # Set minimum support threshold\n",
    "frequent_itemsets = apriori(df, min_support=min_support, use_colnames=True)\n",
    "\n",
    "# Calculate num_itemsets for older versions of association_rules\n",
    "num_itemsets = frequent_itemsets['itemsets'].apply(len).max()\n",
    "\n",
    "# Display frequent itemsets\n",
    "print(\"Frequent Itemsets:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Generate association rules\n",
    "min_confidence = 0.3  # Set minimum confidence threshold\n",
    "rules = association_rules(frequent_itemsets, num_itemsets=num_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "\n",
    "# Display association rules\n",
    "print(\"\\nAssociation Rules:\")\n",
    "print(rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b727b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
