{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LCOFI Algorithm Example**\n",
    "\n",
    "This document explains the implementation of the **LCOFI (Logic Circuit Optimization Frequent Itemset)** algorithm for mining frequent itemsets from a transactional dataset using a graph-based approach.\n",
    "\n",
    "---\n",
    "\n",
    "## **Overview**\n",
    "The **LCOFI algorithm** uses a bipartite graph representation of transactions and items to efficiently mine frequent itemsets. By dynamically pruning infrequent candidates during traversal, it reduces computational overhead and improves performance, especially for large or sparse datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Features**\n",
    "1. **Graph Representation**:\n",
    "   - Transactions and items are represented as nodes.\n",
    "   - Edges connect transactions to the items they contain.\n",
    "\n",
    "2. **Candidate Generation**:\n",
    "   - Candidates are generated by combining frequent subsets iteratively.\n",
    "\n",
    "3. **Support Counting**:\n",
    "   - Support is calculated using graph traversal to count the occurrences of itemsets in transactions.\n",
    "\n",
    "4. **Dynamic Pruning**:\n",
    "   - Itemsets that do not meet the minimum support threshold are pruned dynamically during the process.\n",
    "\n",
    "---\n",
    "\n",
    "## **Implementation Details**\n",
    "### **Steps of the Algorithm**\n",
    "1. **Generate Candidate Itemsets**:\n",
    "   - Combine frequent subsets to generate candidate itemsets for the next level.\n",
    "\n",
    "2. **Count Support**:\n",
    "   - Check how many transactions contain each candidate itemset and calculate its support.\n",
    "\n",
    "3. **Prune Infrequent Itemsets**:\n",
    "   - Remove candidates that do not meet the minimum support threshold.\n",
    "\n",
    "4. **Iterate for Larger Itemsets**:\n",
    "   - Repeat the process for itemsets of increasing sizes until no more frequent itemsets can be generated.\n",
    "\n",
    "---\n",
    "\n",
    "### **Code**\n",
    "The code demonstrates:\n",
    "- Generating candidate itemsets.\n",
    "- Counting support.\n",
    "- Building a bipartite graph for transactions and items.\n",
    "- Iteratively mining frequent itemsets.\n",
    "\n",
    "### **Input Dataset**\n",
    "Sample transactions:\n",
    "```plaintext\n",
    "Transaction 1: {A, B, C}\n",
    "Transaction 2: {A, C}\n",
    "Transaction 3: {B, C, D}\n",
    "Transaction 4: {A, C, D}\n",
    "Transaction 5: {B, C}\n",
    "```\n",
    "\n",
    "### Parameters\n",
    "- transactions: The list of transactions, where each transaction is a set of items.\n",
    "- min_support: The minimum support threshold (e.g., 0.6).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent Itemsets:\n",
      "Level 1:\n",
      "  {'C'}: 1.00\n",
      "  {'A'}: 0.60\n",
      "  {'B'}: 0.60\n",
      "Level 2:\n",
      "  {'C', 'B'}: 0.60\n",
      "  {'C', 'A'}: 0.60\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import networkx as nx\n",
    "\n",
    "# Sample transactional dataset\n",
    "transactions = [\n",
    "    {'A', 'B', 'C'},\n",
    "    {'A', 'C'},\n",
    "    {'B', 'C', 'D'},\n",
    "    {'A', 'C', 'D'},\n",
    "    {'B', 'C'},\n",
    "]\n",
    "\n",
    "# Parameters\n",
    "min_support = 0.6  # Minimum support threshold\n",
    "\n",
    "# Step 1: Generate candidate itemsets\n",
    "def generate_candidates(frequent_itemsets, size):\n",
    "    \"\"\"Generate candidate itemsets of a specific size.\"\"\"\n",
    "    return set(\n",
    "        frozenset(x) for x in itertools.combinations(set(itertools.chain(*frequent_itemsets)), size)\n",
    "    )\n",
    "\n",
    "# Step 2: Count support\n",
    "def count_support(itemsets, transactions):\n",
    "    \"\"\"Count the support of itemsets.\"\"\"\n",
    "    support_counts = {item: 0 for item in itemsets}\n",
    "    for transaction in transactions:\n",
    "        for item in itemsets:\n",
    "            if item.issubset(transaction):\n",
    "                support_counts[item] += 1\n",
    "    return {item: count for item, count in support_counts.items() if count / len(transactions) >= min_support}\n",
    "\n",
    "# Step 3: Generate frequent itemsets\n",
    "def lcofi(transactions, min_support):\n",
    "    \"\"\"LCOFI algorithm for frequent itemsets using graph representation.\"\"\"\n",
    "    # Step 3.1: Represent transactions as a bipartite graph\n",
    "    G = nx.Graph()\n",
    "    for i, transaction in enumerate(transactions):\n",
    "        for item in transaction:\n",
    "            G.add_edge(f\"Transaction_{i}\", item)\n",
    "\n",
    "    # Step 3.2: Start with single-item itemsets\n",
    "    single_items = {frozenset([node]) for node in G if G.degree[node] > 0 and not node.startswith(\"Transaction\")}\n",
    "    frequent_itemsets = count_support(single_items, transactions)\n",
    "\n",
    "    all_frequent_itemsets = [frequent_itemsets]\n",
    "\n",
    "    # Step 3.3: Iteratively generate larger itemsets\n",
    "    k = 2\n",
    "    while frequent_itemsets:\n",
    "        candidates = generate_candidates(frequent_itemsets, k)\n",
    "        frequent_itemsets = count_support(candidates, transactions)\n",
    "        if frequent_itemsets:\n",
    "            all_frequent_itemsets.append(frequent_itemsets)\n",
    "        k += 1\n",
    "\n",
    "    return all_frequent_itemsets\n",
    "\n",
    "# Run the algorithm\n",
    "frequent_itemsets = lcofi(transactions, min_support)\n",
    "\n",
    "# Output results\n",
    "print(\"Frequent Itemsets:\")\n",
    "for k, itemsets in enumerate(frequent_itemsets, start=1):\n",
    "    print(f\"Level {k}:\")\n",
    "    for itemset, support in itemsets.items():\n",
    "        print(f\"  {set(itemset)}: {support / len(transactions):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association Rules:\n",
      "{'C'} => {'B'} (Support: 0.60, Confidence: 0.60, Lift: 1.00)\n",
      "{'B'} => {'C'} (Support: 0.60, Confidence: 1.00, Lift: 1.00)\n",
      "{'C'} => {'A'} (Support: 0.60, Confidence: 0.60, Lift: 1.00)\n",
      "{'A'} => {'C'} (Support: 0.60, Confidence: 1.00, Lift: 1.00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Run the LCOFI algorithm to get frequent itemsets\n",
    "frequent_itemsets = lcofi(transactions, min_support)\n",
    "\n",
    "# Flatten frequent itemsets into a single dictionary\n",
    "flat_itemsets = {}\n",
    "for level in frequent_itemsets:\n",
    "    flat_itemsets.update(level)\n",
    "\n",
    "# Total number of transactions\n",
    "num_transactions = len(transactions)\n",
    "\n",
    "# Prepare the frequent itemsets DataFrame\n",
    "data = {\n",
    "    'itemsets': list(flat_itemsets.keys()),\n",
    "    'support': [support / num_transactions for support in flat_itemsets.values()]  # Normalize support\n",
    "}\n",
    "frequent_itemsets_df = pd.DataFrame(data)\n",
    "\n",
    "# Filter out low or zero-support itemsets\n",
    "frequent_itemsets_df = frequent_itemsets_df[frequent_itemsets_df['support'] > 0]\n",
    "\n",
    "# Add a small epsilon to avoid division by zero\n",
    "epsilon = 1e-10\n",
    "frequent_itemsets_df['support'] += epsilon\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets_df, metric=\"confidence\", min_threshold=0.6, num_itemsets=num_transactions)\n",
    "\n",
    "# Output rules\n",
    "print(\"Association Rules:\")\n",
    "for _, rule in rules.iterrows():\n",
    "    print(f\"{set(rule['antecedents'])} => {set(rule['consequents'])} \"\n",
    "          f\"(Support: {rule['support']:.2f}, Confidence: {rule['confidence']:.2f}, Lift: {rule['lift']:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
